{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convs.0.weight\n",
      "convs.0.bias\n",
      "convs.1.weight\n",
      "convs.1.bias\n",
      "convs.1.running_mean\n",
      "convs.1.running_var\n",
      "convs.1.num_batches_tracked\n",
      "convs.3.weight\n",
      "convs.3.bias\n",
      "convs.4.weight\n",
      "convs.4.bias\n",
      "convs.4.running_mean\n",
      "convs.4.running_var\n",
      "convs.4.num_batches_tracked\n",
      "convs.7.weight\n",
      "convs.7.bias\n",
      "convs.8.weight\n",
      "convs.8.bias\n",
      "convs.8.running_mean\n",
      "convs.8.running_var\n",
      "convs.8.num_batches_tracked\n",
      "convs.12.weight\n",
      "convs.12.bias\n",
      "convs.13.weight\n",
      "convs.13.bias\n",
      "convs.13.running_mean\n",
      "convs.13.running_var\n",
      "convs.13.num_batches_tracked\n",
      "convs.16.weight\n",
      "convs.16.bias\n",
      "convs.17.weight\n",
      "convs.17.bias\n",
      "convs.17.running_mean\n",
      "convs.17.running_var\n",
      "convs.17.num_batches_tracked\n",
      "convs.22.weight\n",
      "convs.22.bias\n",
      "convs.23.weight\n",
      "convs.23.bias\n",
      "convs.23.running_mean\n",
      "convs.23.running_var\n",
      "convs.23.num_batches_tracked\n",
      "convs.26.weight\n",
      "convs.26.bias\n",
      "convs.27.weight\n",
      "convs.27.bias\n",
      "convs.27.running_mean\n",
      "convs.27.running_var\n",
      "convs.27.num_batches_tracked\n",
      "convs.30.weight\n",
      "convs.30.bias\n",
      "convs.31.weight\n",
      "convs.31.bias\n",
      "convs.31.running_mean\n",
      "convs.31.running_var\n",
      "convs.31.num_batches_tracked\n",
      "inception3a.branch1.conv.weight\n",
      "inception3a.branch1.bn.weight\n",
      "inception3a.branch1.bn.bias\n",
      "inception3a.branch1.bn.running_mean\n",
      "inception3a.branch1.bn.running_var\n",
      "inception3a.branch1.bn.num_batches_tracked\n",
      "inception3a.branch2.0.conv.weight\n",
      "inception3a.branch2.0.bn.weight\n",
      "inception3a.branch2.0.bn.bias\n",
      "inception3a.branch2.0.bn.running_mean\n",
      "inception3a.branch2.0.bn.running_var\n",
      "inception3a.branch2.0.bn.num_batches_tracked\n",
      "inception3a.branch2.1.conv.weight\n",
      "inception3a.branch2.1.bn.weight\n",
      "inception3a.branch2.1.bn.bias\n",
      "inception3a.branch2.1.bn.running_mean\n",
      "inception3a.branch2.1.bn.running_var\n",
      "inception3a.branch2.1.bn.num_batches_tracked\n",
      "inception3a.branch3.0.conv.weight\n",
      "inception3a.branch3.0.bn.weight\n",
      "inception3a.branch3.0.bn.bias\n",
      "inception3a.branch3.0.bn.running_mean\n",
      "inception3a.branch3.0.bn.running_var\n",
      "inception3a.branch3.0.bn.num_batches_tracked\n",
      "inception3a.branch3.1.conv.weight\n",
      "inception3a.branch3.1.bn.weight\n",
      "inception3a.branch3.1.bn.bias\n",
      "inception3a.branch3.1.bn.running_mean\n",
      "inception3a.branch3.1.bn.running_var\n",
      "inception3a.branch3.1.bn.num_batches_tracked\n",
      "inception3a.branch4.1.conv.weight\n",
      "inception3a.branch4.1.bn.weight\n",
      "inception3a.branch4.1.bn.bias\n",
      "inception3a.branch4.1.bn.running_mean\n",
      "inception3a.branch4.1.bn.running_var\n",
      "inception3a.branch4.1.bn.num_batches_tracked\n",
      "inception4a.branch1.conv.weight\n",
      "inception4a.branch1.bn.weight\n",
      "inception4a.branch1.bn.bias\n",
      "inception4a.branch1.bn.running_mean\n",
      "inception4a.branch1.bn.running_var\n",
      "inception4a.branch1.bn.num_batches_tracked\n",
      "inception4a.branch2.0.conv.weight\n",
      "inception4a.branch2.0.bn.weight\n",
      "inception4a.branch2.0.bn.bias\n",
      "inception4a.branch2.0.bn.running_mean\n",
      "inception4a.branch2.0.bn.running_var\n",
      "inception4a.branch2.0.bn.num_batches_tracked\n",
      "inception4a.branch2.1.conv.weight\n",
      "inception4a.branch2.1.bn.weight\n",
      "inception4a.branch2.1.bn.bias\n",
      "inception4a.branch2.1.bn.running_mean\n",
      "inception4a.branch2.1.bn.running_var\n",
      "inception4a.branch2.1.bn.num_batches_tracked\n",
      "inception4a.branch3.0.conv.weight\n",
      "inception4a.branch3.0.bn.weight\n",
      "inception4a.branch3.0.bn.bias\n",
      "inception4a.branch3.0.bn.running_mean\n",
      "inception4a.branch3.0.bn.running_var\n",
      "inception4a.branch3.0.bn.num_batches_tracked\n",
      "inception4a.branch3.1.conv.weight\n",
      "inception4a.branch3.1.bn.weight\n",
      "inception4a.branch3.1.bn.bias\n",
      "inception4a.branch3.1.bn.running_mean\n",
      "inception4a.branch3.1.bn.running_var\n",
      "inception4a.branch3.1.bn.num_batches_tracked\n",
      "inception4a.branch4.1.conv.weight\n",
      "inception4a.branch4.1.bn.weight\n",
      "inception4a.branch4.1.bn.bias\n",
      "inception4a.branch4.1.bn.running_mean\n",
      "inception4a.branch4.1.bn.running_var\n",
      "inception4a.branch4.1.bn.num_batches_tracked\n",
      "inception4b.branch1.conv.weight\n",
      "inception4b.branch1.bn.weight\n",
      "inception4b.branch1.bn.bias\n",
      "inception4b.branch1.bn.running_mean\n",
      "inception4b.branch1.bn.running_var\n",
      "inception4b.branch1.bn.num_batches_tracked\n",
      "inception4b.branch2.0.conv.weight\n",
      "inception4b.branch2.0.bn.weight\n",
      "inception4b.branch2.0.bn.bias\n",
      "inception4b.branch2.0.bn.running_mean\n",
      "inception4b.branch2.0.bn.running_var\n",
      "inception4b.branch2.0.bn.num_batches_tracked\n",
      "inception4b.branch2.1.conv.weight\n",
      "inception4b.branch2.1.bn.weight\n",
      "inception4b.branch2.1.bn.bias\n",
      "inception4b.branch2.1.bn.running_mean\n",
      "inception4b.branch2.1.bn.running_var\n",
      "inception4b.branch2.1.bn.num_batches_tracked\n",
      "inception4b.branch3.0.conv.weight\n",
      "inception4b.branch3.0.bn.weight\n",
      "inception4b.branch3.0.bn.bias\n",
      "inception4b.branch3.0.bn.running_mean\n",
      "inception4b.branch3.0.bn.running_var\n",
      "inception4b.branch3.0.bn.num_batches_tracked\n",
      "inception4b.branch3.1.conv.weight\n",
      "inception4b.branch3.1.bn.weight\n",
      "inception4b.branch3.1.bn.bias\n",
      "inception4b.branch3.1.bn.running_mean\n",
      "inception4b.branch3.1.bn.running_var\n",
      "inception4b.branch3.1.bn.num_batches_tracked\n",
      "inception4b.branch4.1.conv.weight\n",
      "inception4b.branch4.1.bn.weight\n",
      "inception4b.branch4.1.bn.bias\n",
      "inception4b.branch4.1.bn.running_mean\n",
      "inception4b.branch4.1.bn.running_var\n",
      "inception4b.branch4.1.bn.num_batches_tracked\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NetModel:\n\tsize mismatch for convs.0.weight: copying a param with shape torch.Size([3, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-6ec2e220708c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlays1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0mnet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/inception1-0.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0mnet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchvision/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for NetModel:\n\tsize mismatch for convs.0.weight: copying a param with shape torch.Size([3, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 3])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "\tdef __init__(self, in_channels, out_channels, **kwargs):\n",
    "\t\tsuper(BasicConv2d, self).__init__()\n",
    "\t\tself.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "\t\tself.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.conv(x)\n",
    "\t\tx = self.bn(x)\n",
    "\t\treturn F.relu(x, inplace=True)\n",
    "\n",
    "class Inception(nn.Module): \n",
    "\n",
    "\tdef __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
    "\t\tsuper(Inception, self).__init__()\n",
    "\n",
    "\t\tself.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "\t\tself.branch2 = nn.Sequential(\n",
    "\t\t\tBasicConv2d(in_channels, ch3x3red, kernel_size=1),\n",
    "\t\t\tBasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.branch3 = nn.Sequential(\n",
    "\t\t\tBasicConv2d(in_channels, ch5x5red, kernel_size=1),\n",
    "\t\t\tBasicConv2d(ch5x5red, ch5x5, kernel_size=3, padding=1)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.branch4 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=3, stride=1, padding=1,ceil_mode=True),\n",
    "\t\t\tBasicConv2d(in_channels, pool_proj, kernel_size=1)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tbranch1 = self.branch1(x)\n",
    "\t\tbranch2 = self.branch2(x)\n",
    "\t\tbranch3 = self.branch3(x)\n",
    "\t\tbranch4 = self.branch4(x)\n",
    "\n",
    "\t\toutputs = [branch1, branch2, branch3, branch4]\n",
    "\t\treturn torch.cat(outputs, 1)\n",
    "    \n",
    "convs = nn.Sequential(\n",
    "    nn.Conv2d(3, 3, (1,1)),\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(3, 64, (3, 3)),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),  # relu1-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 64, (3, 3)),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),  # relu1-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 128, (3, 3)),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),  # relu2-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 128, (3, 3)),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),  # relu2-2\n",
    "    nn.Dropout(0.4),\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 256, (3, 3)),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),  # relu3-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),  # relu3-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),  # relu3-3 \n",
    "    nn.Dropout(0.4),\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(256, 512, (3, 3)),\n",
    "#     nn.BatchNorm2d(512),\n",
    "#     nn.ReLU(),  # relu4-1\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(512, 512, (3, 3)),\n",
    "#     nn.BatchNorm2d(512),\n",
    "#     nn.ReLU(),  # relu4-2\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    ")\n",
    "\n",
    "class NetModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NetModel, self).__init__()\n",
    "\n",
    "\t\tself.convs = convs\n",
    "\t\t# self.inception = models.inception_v3(pretrained=False)\n",
    "\t\tself.inception3a = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "\t\tself.inception4a = Inception(480, 192, 96, 208, 16, 48 ,64)\n",
    "\t\tself.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "\t\t# self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "\t\tself.pool = nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True)\n",
    "\t\tself.fc1 = nn.Linear(512 * 2 * 2, 4096)\n",
    "\t\tself.fc2 = nn.Linear(4096, 512)\n",
    "\t\tself.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\n",
    "\t\tx = self.convs(x)\n",
    "\t\t# 256 x 4 x 4\n",
    "\t\tx = self.inception3a(x)\n",
    "\t\t# 480 x 4 x 4\n",
    "\t\tx = self.inception4a(x)\n",
    "\t\t# 512 x 4 x 4 \n",
    "\t\tx = self.inception4b(x)\n",
    "\t\t# 512 x 4 x 4\n",
    "\t\t# x = self.inception4c(x)\n",
    "\t\t# 512 x 4 x 4\n",
    "\t\tx = self.pool(x)\n",
    "\n",
    "\t\tx = x.view(-1, 512 * 2 * 2)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = self.fc3(x)\n",
    "\t\treturn x\n",
    "net1 = NetModel()\n",
    "net1.eval()\n",
    "\n",
    "lays1=(torch.load('./models/inception1-0.pth'))\n",
    "for lay in lays1:\n",
    "    print(lay)\n",
    "net1.load_state_dict(torch.load('./models/inception1-0.pth'))\n",
    "net1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "\t[transforms.ToTensor(),\n",
    "\t transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=20, shuffle=False, num_workers=2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net1(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        accu = 100 * correct / total\n",
    "    print('accuracy: %d %%' % (accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
