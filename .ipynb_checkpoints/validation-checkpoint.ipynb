{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convs1.0.weight\n",
      "convs1.0.bias\n",
      "convs1.0.running_mean\n",
      "convs1.0.running_var\n",
      "convs1.0.num_batches_tracked\n",
      "convs1.3.weight\n",
      "convs1.3.bias\n",
      "convs1.4.weight\n",
      "convs1.4.bias\n",
      "convs1.4.running_mean\n",
      "convs1.4.running_var\n",
      "convs1.4.num_batches_tracked\n",
      "convs1.7.weight\n",
      "convs1.7.bias\n",
      "convs1.8.weight\n",
      "convs1.8.bias\n",
      "convs1.8.running_mean\n",
      "convs1.8.running_var\n",
      "convs1.8.num_batches_tracked\n",
      "convs1.11.weight\n",
      "convs1.11.bias\n",
      "convs1.12.weight\n",
      "convs1.12.bias\n",
      "convs1.12.running_mean\n",
      "convs1.12.running_var\n",
      "convs1.12.num_batches_tracked\n",
      "convs1.17.weight\n",
      "convs1.17.bias\n",
      "convs1.18.weight\n",
      "convs1.18.bias\n",
      "convs1.18.running_mean\n",
      "convs1.18.running_var\n",
      "convs1.18.num_batches_tracked\n",
      "convs1.21.weight\n",
      "convs1.21.bias\n",
      "convs1.22.weight\n",
      "convs1.22.bias\n",
      "convs1.22.running_mean\n",
      "convs1.22.running_var\n",
      "convs1.22.num_batches_tracked\n",
      "inception1.branch1.conv.weight\n",
      "inception1.branch1.bn.weight\n",
      "inception1.branch1.bn.bias\n",
      "inception1.branch1.bn.running_mean\n",
      "inception1.branch1.bn.running_var\n",
      "inception1.branch1.bn.num_batches_tracked\n",
      "inception1.branch2.0.conv.weight\n",
      "inception1.branch2.0.bn.weight\n",
      "inception1.branch2.0.bn.bias\n",
      "inception1.branch2.0.bn.running_mean\n",
      "inception1.branch2.0.bn.running_var\n",
      "inception1.branch2.0.bn.num_batches_tracked\n",
      "inception1.branch2.1.conv.weight\n",
      "inception1.branch2.1.bn.weight\n",
      "inception1.branch2.1.bn.bias\n",
      "inception1.branch2.1.bn.running_mean\n",
      "inception1.branch2.1.bn.running_var\n",
      "inception1.branch2.1.bn.num_batches_tracked\n",
      "inception1.branch3.0.conv.weight\n",
      "inception1.branch3.0.bn.weight\n",
      "inception1.branch3.0.bn.bias\n",
      "inception1.branch3.0.bn.running_mean\n",
      "inception1.branch3.0.bn.running_var\n",
      "inception1.branch3.0.bn.num_batches_tracked\n",
      "inception1.branch3.1.conv.weight\n",
      "inception1.branch3.1.bn.weight\n",
      "inception1.branch3.1.bn.bias\n",
      "inception1.branch3.1.bn.running_mean\n",
      "inception1.branch3.1.bn.running_var\n",
      "inception1.branch3.1.bn.num_batches_tracked\n",
      "inception1.branch4.1.conv.weight\n",
      "inception1.branch4.1.bn.weight\n",
      "inception1.branch4.1.bn.bias\n",
      "inception1.branch4.1.bn.running_mean\n",
      "inception1.branch4.1.bn.running_var\n",
      "inception1.branch4.1.bn.num_batches_tracked\n",
      "inception2.branch1.conv.weight\n",
      "inception2.branch1.bn.weight\n",
      "inception2.branch1.bn.bias\n",
      "inception2.branch1.bn.running_mean\n",
      "inception2.branch1.bn.running_var\n",
      "inception2.branch1.bn.num_batches_tracked\n",
      "inception2.branch2.0.conv.weight\n",
      "inception2.branch2.0.bn.weight\n",
      "inception2.branch2.0.bn.bias\n",
      "inception2.branch2.0.bn.running_mean\n",
      "inception2.branch2.0.bn.running_var\n",
      "inception2.branch2.0.bn.num_batches_tracked\n",
      "inception2.branch2.1.conv.weight\n",
      "inception2.branch2.1.bn.weight\n",
      "inception2.branch2.1.bn.bias\n",
      "inception2.branch2.1.bn.running_mean\n",
      "inception2.branch2.1.bn.running_var\n",
      "inception2.branch2.1.bn.num_batches_tracked\n",
      "inception2.branch3.0.conv.weight\n",
      "inception2.branch3.0.bn.weight\n",
      "inception2.branch3.0.bn.bias\n",
      "inception2.branch3.0.bn.running_mean\n",
      "inception2.branch3.0.bn.running_var\n",
      "inception2.branch3.0.bn.num_batches_tracked\n",
      "inception2.branch3.1.conv.weight\n",
      "inception2.branch3.1.bn.weight\n",
      "inception2.branch3.1.bn.bias\n",
      "inception2.branch3.1.bn.running_mean\n",
      "inception2.branch3.1.bn.running_var\n",
      "inception2.branch3.1.bn.num_batches_tracked\n",
      "inception2.branch4.1.conv.weight\n",
      "inception2.branch4.1.bn.weight\n",
      "inception2.branch4.1.bn.bias\n",
      "inception2.branch4.1.bn.running_mean\n",
      "inception2.branch4.1.bn.running_var\n",
      "inception2.branch4.1.bn.num_batches_tracked\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NetModel(\n",
       "  (convs1): Sequential(\n",
       "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
       "    (2): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
       "    (15): Dropout(p=0.4)\n",
       "    (16): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU()\n",
       "    (20): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU()\n",
       "    (24): Dropout(p=0.5)\n",
       "    (25): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (inception1): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(3, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(18, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(3, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(18, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(18, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(36, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(3, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(6, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(6, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(9, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception2): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(64, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(6, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(6, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
       "  (fc1): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "class NetModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NetModel, self).__init__()\n",
    "\n",
    "\t\tself.convs1 = nn.Sequential(\n",
    "\t\t\t# nn.Conv2d(3, 3, (1, 1)),\n",
    "   #  \tnn.BatchNorm2d(3),\n",
    "   #  \tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "   #  \tnn.Conv2d(3, 64, (3, 3)),\n",
    "   #  \tnn.BatchNorm2d(64),\n",
    "   #  \tnn.ReLU(),  # relu1-1\n",
    "   #  \tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\n",
    "   \t\t# nn.BatchNorm2d(64),\n",
    "    \t# nn.Conv2d(64, 64, (3, 3)),\n",
    "    \t# nn.BatchNorm2d(64),\n",
    "    \t# nn.ReLU(),\n",
    "    \t# nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "\n",
    "    \tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    \tnn.Conv2d(64, 128, (3, 3)),\n",
    "    \tnn.BatchNorm2d(128),\n",
    "    \tnn.ReLU(),\n",
    "    \tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    \tnn.Conv2d(128, 128, (3, 3)),\n",
    "    \tnn.BatchNorm2d(128),\n",
    "    \tnn.ReLU(),  # relu2-2\n",
    "    \tnn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "\n",
    "    \tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    \tnn.Conv2d(128, 256, (3, 3)),\n",
    "    \tnn.BatchNorm2d(256),\n",
    "    \tnn.ReLU(),  # relu3-1\n",
    "    \tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\n",
    "    \tnn.Conv2d(256, 256, (3, 3)),\n",
    "    \tnn.BatchNorm2d(256),\n",
    "    \tnn.ReLU(),  # relu3-2\n",
    "    \tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    \tnn.Conv2d(256, 256, (3, 3)),\n",
    "    \tnn.BatchNorm2d(256),\n",
    "    \tnn.ReLU(),  # relu3-3 \n",
    "    \tnn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    \tnn.Dropout(0.4),\n",
    "  \t\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    \tnn.Conv2d(256, 512, (3, 3)),\n",
    "    \tnn.BatchNorm2d(512),\n",
    "    \tnn.ReLU(),  # relu4-1\n",
    "    \tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    \tnn.Conv2d(512, 512, (3, 3)),\n",
    "    \tnn.BatchNorm2d(512),\n",
    "    \tnn.ReLU(),  # relu4-2\n",
    "    \tnn.Dropout(0.5),\n",
    "    \tnn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "\t\t)\n",
    "\n",
    "\t\tself.inception1 = Inception(3, 18, 18, 36, 6, 9, 1) #18 + 36 + 9 + 1 = 64\n",
    "\t\t# self.inception2 = Inception(64, 16, 16, 32, 6, 8 ,8)#16 + 32 + 8 + 8 = 64\n",
    "\t\tself.inception2 = Inception(64, 32, 40, 80, 6, 8, 8)#32 + 64 + 8 + 8 = 128\n",
    "\t\t# self.inception4 = Inception(128, 32, 32, 64, 12, 16, 16)#32 + 64 + 16 + 16 = 128\n",
    "\t\t# self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "\t\tself.pool = nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True)\n",
    "\t\tself.fc1 = nn.Linear(512 * 2 * 2, 4096)\n",
    "\t\tself.fc2 = nn.Linear(4096, 512)\n",
    "\t\tself.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\n",
    "\t\t# 3 x 32 x 32\n",
    "\t\tx = self.inception1(x)\n",
    "\t\t# 64 x 32 x 32\n",
    "\t\tx = self.inception2(x)\n",
    "\t\t# 64 x 32 x 32 \n",
    "\t\tx = self.pool(x)\n",
    "\t\t# 64 x 16 x 16\n",
    "\t\t# x = self.inception3(x)\n",
    "\t\t# 128 x 16 x 16\n",
    "\t\t# x = self.inception4(x)\n",
    "\t\t# 128 x 16 x 16\n",
    "\t\tx = self.convs1(x)\n",
    "\t\t# 512 x 2 x 2\n",
    "\n",
    "\t\tx = x.view(-1, 512 * 2 * 2)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = self.fc3(x)\n",
    "\t\treturn x\n",
    "net1 = NetModel()\n",
    "net1.eval()\n",
    "\n",
    "lays1=(torch.load('./models/inception-f6.pth'))\n",
    "for lay in lays1:\n",
    "    print(lay)\n",
    "net1.load_state_dict(torch.load('./models/inception-f6.pth'))\n",
    "net1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "\t[transforms.ToTensor(),\n",
    "\t transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=40, shuffle=False, num_workers=2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net1(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        accu = 100 * correct / total\n",
    "    print('accuracy: %d %%' % (accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
